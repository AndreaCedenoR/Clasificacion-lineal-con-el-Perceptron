# ‚úÖ Secci√≥n I ‚Äì Cargar el dataset ‚Äúwine‚Äù de Scikit-learn

# Importar librer√≠as
from sklearn.datasets import load_wine
import pandas as pd

# Cargar el dataset wine
wine = load_wine()
df = pd.DataFrame(wine.data, columns=wine.feature_names)
df['target'] = wine.target

# Mostrar las primeras filas
# df.head()
df.sample(10)  # Muestra 10 filas aleatorias, de cualquier clase

# Se importa el conjunto de datos wine que contiene informaci√≥n sobre vinos de 3 clases.
# Se crea un DataFrame de pandas con las caracter√≠sticas y la etiqueta (target), que representa el tipo de vino (0, 1 o 2).

# ‚úÖ Secci√≥n II ‚Äì Seleccionar las caracter√≠sticas deseadas

features = ['alcohol', 'magnesium', 'color_intensity']
df_selected = df[features + ['target']]

# df_selected.head()
df_selected.sample(10)

# Nos enfocamos en 3 caracter√≠sticas: alcohol, magnesium y color_intensity, como base para entrenar un clasificador.
# Estas caracter√≠sticas son num√©ricas y ayudan a diferenciar los tipos de vino.

# ‚úÖ Secci√≥n III ‚Äì Seleccionar dos clases para clasificaci√≥n binaria

df_binary = df_selected[df_selected['target'].isin([0, 1])]

# Variables predictoras y objetivo
X = df_binary[features].values
y = df_binary['target'].values

# El dataset wine tiene 3 clases (0, 1, 2), pero necesitamos una clasificaci√≥n binaria, as√≠ que seleccionamos solo las clases 0 y 1.
# X es la matriz de caracter√≠sticas, e y es el vector de etiquetas (0 o 1).

# ‚úÖ Secci√≥n IV - Divida la data en dos subconjuntos: uno de entrenamiento y uno de prueba

from sklearn.model_selection import train_test_split

# Divisi√≥n de datos en entrenamiento (80%) y prueba (20%)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Se dividen los datos de entrenamiento manteniendo proporcionalidad

# ‚úÖ Secci√≥n V - Usando los datos de entrenamiento, implemente un clasificador binario, basado en el algoritmo del Perceptr√≥n Simple.


import numpy as np

# Convertir etiquetas de 0 y 1 a -1 y 1 para compatibilidad con el algoritmo
y_train_bin = np.where(y_train == 0, -1, 1)

# Inicializar pesos y sesgo
weights = np.zeros(X_train.shape[1])
bias = 0

# Hiperpar√°metros
learning_rate = 0.01
epochs = 100

# Entrenamiento
for epoch in range(epochs):
    for xi, target in zip(X_train, y_train_bin):
        activation = np.dot(xi, weights) + bias
        prediction = np.sign(activation)
        if prediction != target:
            weights += learning_rate * target * xi
            bias += learning_rate * target

# Utilizando el algoritmo de clasificaci√≥n binaria supervisado, donde su f√≥rmula es:
# y‚Äã=sign(wT‚ãÖx+b) 

# donde:

# ùë• es el vector de caracter√≠sticas de entrada.

# ùë§ son los pesos del modelo.

# ùëè es el sesgo (bias).

# sign ( ) devuelve +1 o -1 (nosotros adaptaremos a 0 o 1).

# Esto √∫ltimo porque el Perceptr√≥n de Rosenblatt toma decisiones usando el signo de esta expresi√≥n:

# y‚Äã=sign(w‚ãÖx+b) 

# Y luego actualiza los pesos solo si se equivoca usando esta regla:

# w‚Üêw+Œ∑‚ãÖy‚ãÖx 

# Donde:

# ùë¶ es la etiqueta real, que debe ser -1 o 1

# ùúÇ es la tasa de aprendizaje

# ùë• es el vector de caracter√≠sticas

# Si ùë¶ ‚àà { 0 , 1 } y‚àà{0,1}, esta f√≥rmula no funciona correctamente, porque por ejemplo:

# Si ùë¶ = 0 y=0, entonces ùë¶ ‚ãÖ ùë• = 0 y‚ãÖx=0, y los pesos no se actualizan nunca.


# ‚úÖ Secci√≥n VI - Usando los datos de prueba, evalue el desempe√±o del algoritmo y mu√©strelo a trav√©s de una matriz de confusi√≥n.

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Convertir etiquetas de prueba a -1 y 1
y_test_bin = np.where(y_test == 0, -1, 1)

# Funci√≥n de predicci√≥n
def predict(X, weights, bias):
    linear_output = np.dot(X, weights) + bias
    return np.where(linear_output >= 0, 1, -1)  # Aplicar funci√≥n escal√≥n

# Predecir sobre los datos de prueba
y_pred_bin = predict(X_test, weights, bias)

# Calcular y mostrar matriz de confusi√≥n
cm = confusion_matrix(y_test_bin, y_pred_bin)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Clase -1 (original 0)", "Clase 1 (original 1)"])
disp.plot()
plt.title("Matriz de Confusi√≥n - Perceptr√≥n Manual")
plt.grid(False)
plt.show()

# Importaci√≥n de librer√≠as: Se importan las funciones confusion_matrix y ConfusionMatrixDisplay de sklearn.metrics para calcular y visualizar la matriz de confusi√≥n. Tambi√©n se importa matplotlib.pyplot para personalizar la visualizaci√≥n.

# Conversi√≥n de etiquetas: Como el Perceptr√≥n cl√°sico trabaja con etiquetas binarias -1 y 1, se transforman las etiquetas originales de prueba (0 y 1) en -1 y 1 respectivamente.

# Definici√≥n de la funci√≥n de predicci√≥n: Se implementa la funci√≥n predict, que aplica la regla del Perceptr√≥n:

# Calcula la salida lineal: ùë§ ‚ãÖ ùë• + ùëè

# Aplica la funci√≥n escal√≥n: devuelve 1 si la salida es mayor o igual que 0, y -1 en caso contrario.

# Predicciones sobre el conjunto de prueba: Se usa la funci√≥n anterior junto con los pesos y el sesgo aprendidos durante el entrenamiento para predecir las etiquetas de los datos de prueba.

# C√°lculo y visualizaci√≥n de la matriz de confusi√≥n: Se compara el vector de etiquetas verdaderas con el de predicciones, para generar una matriz de confusi√≥n. Luego, se visualiza gr√°ficamente, indicando cu√°ntas predicciones fueron correctas y cu√°ntas incorrectas para cada clase.


# ‚úÖ Secci√≥n VII - Usando los datos de prueba, evalue el desempe√±o del algoritmo y mu√©strelo a trav√©s de una matriz de confusi√≥n.

from sklearn.linear_model import Perceptron
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Crear el modelo de Perceptr√≥n
clf = Perceptron(max_iter=1000, eta0=0.1, random_state=42)

# Entrenar el modelo con los datos originales (etiquetas 0 y 1)
clf.fit(X_train, y_train)

# Realizar predicciones sobre los datos de prueba
y_pred_sklearn = clf.predict(X_test)

# Calcular y mostrar matriz de confusi√≥n
cm = confusion_matrix(y_test, y_pred_sklearn)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Clase 0", "Clase 1"])
disp.plot()
plt.title("Matriz de Confusi√≥n - Perceptr√≥n Scikit-learn")
plt.grid(False)
plt.show()


# En esta secci√≥n se utiliza la clase Perceptron de scikit-learn, una implementaci√≥n optimizada del algoritmo del Perceptr√≥n para clasificaci√≥n supervisada. A continuaci√≥n se describen los pasos principales:

# Creaci√≥n del modelo: Se inicializa un objeto de tipo Perceptron con:

# max_iter=1000: n√∫mero m√°ximo de iteraciones para el entrenamiento.

# eta0=0.1: tasa de aprendizaje.

# random_state=42: semilla para asegurar la reproducibilidad de los resultados.

# Entrenamiento: Se entrena el modelo utilizando X_train y y_train. A diferencia de nuestro Perceptr√≥n manual, aqu√≠ no es necesario convertir las etiquetas a -1 y 1; scikit-learn puede trabajar directamente con 0 y 1.

# Predicci√≥n: Se usan los datos de prueba X_test para predecir las etiquetas correspondientes (y_pred_sklearn).

# Evaluaci√≥n con matriz de confusi√≥n: Se calcula la matriz de confusi√≥n, que muestra c√≥mo el modelo clasifica cada clase. Esto permite comparar visualmente su rendimiento con el Perceptr√≥n manual.














